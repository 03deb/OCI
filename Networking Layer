Networking Diagram -> https://k21academy.com/wp-content/uploads/2018/10/PublicPrivateSubnet_D2-e1603279823526.png

{ Load Balancer }

A Load Balancer in OCI is a fully managed, highly available network service that automatically distributes incoming application traffic across multiple backend resources
-> No single server gets overwhelmed
-> Applications run faster and stay available even if one server fails
Example: Think of it like a traffic cop standing at a fork in the road, directing cars (requests) to less busy streets (servers).

# In Oracle Cloud Infrastructure (OCI), the OCI Load Balancer is a fully managed, highly available service that distributes traffic across multiple compute instances (VMs).
It supports:
Layer 4 (TCP) - Network-level traffic
Layer 7 (HTTP/HTTPS) - Application-level traffic

# Types of OCI Load Balancers
-> Public Load Balancer: Exposes applications to the internet; has a public IP address.
-> Private Load Balancer: Used for internal traffic within a Virtual Cloud Network (VCN); has a private IP address.

# Why Do We Use a Load Balancer?
-> High Availability: If one backend server fails, traffic is rerouted to healthy servers.
-> Scalability: Easily handle more traffic by adding more backend servers without changing client configuration.
-> Fault Tolerance: Minimizes application downtime.
-> Security: Hides backend server details (IP, architecture) from clients.
-> Simplified Management: Centralizes traffic management, SSL termination, and routing logic.
-> Efficient Resource Utilization: Distributes workloads evenly among backend resources.

# Real-World Example: Hosting a Website
Scenario: You're building a shopping website like Amazon.
You deploy:
• 3 Compute Instances (VMs) running your website's backend
Problem: If you send all traffic to only one of them, it may slow down or crash.

Solution: Add a Load Balancer
You set up a Public Load Balancer in front of the 3 instances.

      Now:
                      Clients (Internet)
                            |
                      [Public IP: Load Balancer]
                            |
                      --------------------------
                      |           |           |
                      VM1       VM2         VM3


# What Happens if We Use a Load Balancer:
1. A user visits your website.
2. The Load Balancer receives the request.
3. It checks which backend server is healthy and less busy.
4. Forwards the request accordingly.
If one backend goes down, traffic automatically routes to the remaining healthy ones - users won't even notice.

# What Happens If We Don’t Use a Load Balancer?
1. Single Point of Failure: If a backend server fails, users lose access.
2. Maintenance Complexity: Updating or scaling requires manual reconfiguration for clients.
3. No Health Checks: Clients may connect to unhealthy or offline servers.
4. Poor Scalability: Hard to handle spikes in user traffic efficiently.
5. Limited Security: Exposes backend server IPs and structure to the public.

# In summary:
A Load Balancer in OCI is essential for building reliable, scalable, and secure cloud-native applications. It simplifies management, enhances fault tolerance, and hides 
infrastructure details from users, making it a best practice for any multi-instance deployment.

________________________________________________________________________________________________________________________________________________________________________

Here's a breakdown of the 7 layers:

1. Physical Layer:
Deals with the physical connection between devices, including the transmission of raw bitstreams over a physical medium (cables, etc.). 

2. Data Link Layer:
Responsible for error-free transfer of data frames between two directly connected nodes, handling access to the physical medium. 

3. Network Layer:
Manages the routing of data packets between different networks, using logical addresses (IP addresses) to find the best path. 

4. Transport Layer:
Provides reliable or unreliable delivery of data segments, managing flow control, error control, and segmentation/desegmentation. 

5. Session Layer:
Establishes, manages, and terminates connections (sessions) between applications. 

6. Presentation Layer:
Handles data representation, including encryption, decryption, compression, and translation of data formats to ensure interoperability between systems. 

7. Application Layer:
The interface between the user and the network, providing services like email, file transfer, and web browsing. 

# Network Layer (Layer 3) :-
The network layer works for the transmission of data from one host to the other located in different networks. It also takes care of packet routing i.e. selection 
of the shortest path to transmit the packet, from the number of routes available.

* Protocols at this Layer:
-> IPv4 / IPv6 (Internet Protocol): Provides logical addressing and routing.
-> ICMP (Internet Control Message Protocol): Used for sending error messages and operational information (e.g., ping).
-> IPsec: For secure IP communications.

Example:
Imagine you send an email from your office computer in New York to a colleague in London. The Network Layer on your computer assigns the destination IP address 
(for the London computer) and determines the route—possibly through several routers and networks—until the email reaches its destination.

Real-life analogy:
It’s like addressing a letter with both the sender and receiver’s street addresses and relying on the postal system to determine the best route from your city to 
another country.

# Transport Layer (Layer 4) :-
It is responsible for the end-to-end delivery of the complete message. The transport layer also provides the acknowledgment of the successful data transmission 
and re-transmits the data if an error is found.

* Protocols at this Layer:
-> TCP (Transmission Control Protocol): Reliable, connection-oriented protocol (used for web browsing, email, file transfers).
-> UDP (User Datagram Protocol): Unreliable, connectionless protocol (used for real-time applications like video, voice calls, online games).

Example:
When you open a website (like www.example.com), your browser uses TCP to connect to the web server. TCP ensures that all the pieces (segments) of the webpage 
arrive intact and in the right order. If a piece is missing or corrupted, TCP requests it again.

Real-life analogy:
It’s like a phone conversation where both people confirm that they hear each other clearly and ask for repetition if something is missed.

In summary:
The Network Layer finds the best path for data across networks using IP addresses.
The Transport Layer ensures data gets to the right application, reliably and in order, using protocols like TCP and UDP.
________________________________________________________________________________________________________________________________________________________________________

{ Network Load Balancer }

-> A Network Load Balancer (NLB) in OCI is a highly performant, low-latency load balancer that Operates at Layer 3/4 (network and transport layers) of the OSI model, 
specifically handling TCP, UDP, and ICMP traffic.

✅ Use Case Example (Real-World) :
Scenario: Gaming Server Load Balancing
Suppose you are running a multiplayer game server that uses UDP for fast communication between players.
You deploy:
-> 3 compute instances in OCI running your game backend (UDP-based)
-> You want to distribute player traffic evenly across these instances

Solution: Use a Network Load Balancer
PLAYER → NLB (UDP port 9000) → Game Server 1 
(UDP 9000)                   → Game Server 2                            
(UDP 9000)                   → Game Server 3 

Without NLB:
-> Each player is assigned a specific game server’s IP and port.
-> If a server fails, those players are disconnected and can’t reconnect automatically.

Why Network LB here?
-> HTTP Load Balancer (Layer 7) cannot handle UDP
-> NLB handles it efficiently without inspecting the content


Why is NLB Necessary?
-> Essential for Non-HTTP Traffic: If your application uses TCP/UDP protocols (like databases, custom apps, or gaming servers), NLB is required since an application
load balancer might not support or efficiently handle these protocols.
-> Performance-Critical Environments: For scenarios demanding ultra-low latency and very high throughput, NLB is the best fit.
-> Source IP Requirements: Some security or audit requirements demand that backend servers see the real client IP, which NLB provides.
-> Simplicity: For straightforward, protocol-agnostic traffic distribution (no need for SSL offloading, path-based routing, etc.), NLB is simpler and more efficient.


When to Use NLB in OCI
-> For any workload that is not web-based (non-HTTP/HTTPS), such as databases, VoIP, custom TCP/UDP applications, and gaming.
-> When ultra-low latency and high throughput are required.
-> When backend applications require the client’s source IP.
-> For applications needing to handle millions of concurrent connections.


How is NLB Different from "Normal" (Application) Load Balancer?

Feature                |	Network Load Balancer (NLB)       |	Application Load Balancer (ALB) (OCI LBaaS)
------------------------------------------------------------------------------------------------------------
OSI Layer	           |  Layer 4 (Transport/Network)           |	Layer 7 (Application)
Supported Protocols    |  TCP, UDP, ICMP	                      | HTTP, HTTPS, WebSockets, SSL/TLS termination
Traffic Routing	     |  Based on IP, port                     | Based on URL, Host, Cookies, Application data
SSL Termination	     |  No         	                      | Yes
Source IP Preservation |  Yes	                                  | No (unless using X-Forwarded-For header)
Performance	           |  Very high, low latency	          | Moderate, higher processing due to application logic
Health Checks	     |  Basic (TCP/UDP)	                      | Advanced (HTTP, HTTPS, path-based)
Use Cases	           |  Non-HTTP workloads, gaming, VoIP      | Web apps, APIs, HTTPS termination, cookie-based routing


_________________________________________________________________________________________________________________________________________________________________________

{ Application Level Load Balancer (ALB)? }
-> An Application Level Load Balancer operates at the Application Layer (Layer 7) of the OSI model. This means it can inspect and make decisions based on the content of the 
application data (such as HTTP headers, cookies, URLs), not just on IP addresses and ports.

In OCI and other clouds, this is often just called a "Load Balancer" or "Layer 7 Load Balancer."


# Real-World Example: E-commerce Website
Let’s say you run an online store like Flipkart.
You have:
-> One backend for product listing: /products
-> One backend for shopping cart: /cart
-> One backend for checkout: /checkout
# Without Load Balancer:
Users talk directly to one server — bad for reliability and scalability.
# With Application-Level Load Balancer:
User → HTTPS Request → Load Balancer
      ├─> /products  → App Server 1
      ├─> /cart      → App Server 2
      └─> /checkout  → App Server 3

Here the load balancer reads the URL and forwards traffic to the correct backend.

# Key Features of Application Load Balancer
-> Content-based Routing: Routes requests based on URL, host, HTTP headers, cookies, etc.
-> SSL/TLS Termination: Can decrypt HTTPS traffic, offloading the work from backend servers.
-> Session Persistence (Sticky Sessions): Can keep a user’s requests going to the same backend server.
-> Advanced Health Checks: Can check specific URLs/endpoints for health, not just open ports.
-> WebSocket Support: Handles modern web communication protocols.
-> Rewrite/Redirect: Can modify headers or redirect requests.


Why Use an Application Load Balancer?
Flexibility: Route traffic based on application data (URLs, headers, cookies).
Security: Centralized SSL certificate management and traffic termination.
Health Monitoring: More precise health checks using HTTP responses.
Scalability: Easily add or remove backend servers as demand changes.
User Experience: Sticky sessions and content-based routing for better performance and reliability.

__________________________________________________________________________________________________________________________________________________________________________

In-Depth Explanation

1. Round Robin
How: Each server gets requests in turn, cycling through all servers.
Pros: Simple, easy to implement; good for evenly distributed, quick requests.
Cons: Doesn’t account for variable connection times or server health—can overload a slower server.

2. Least Connections
How: New request goes to the server with the fewest active (open) connections.
Pros: Better for long-lived or variable-length requests; helps ensure no server gets too many active sessions at once.
Cons: “Active connections” isn't always a perfect measure of server load (especially with idle TCP connections).

3. IP Hash
How: Hashes the client’s IP to pick a server, so the same client always hits the same backend (as long as it’s up).
Pros: Great for keeping sessions sticky; useful for stateful applications.
Cons: If many clients share an IP (like behind a proxy or NAT), one server may get overloaded.

Summary
Round Robin: Good for simple, stateless workloads.
Least Connections: Good for applications with varying request durations or resource use.
IP Hash: Good for sticky sessions, but watch out for proxies/NAT.

____________________________________________________________________________________________________________________________________________________________________________


✅ 1. Public Load Balancer

📘 Definition:
A Public Load Balancer has a public IP address and is accessible from the internet. It acts as the front door to your applications hosted in OCI.

🌐 When to Use It:

Use a public load balancer when you want users on the internet to access your:
Websites
APIs
Web applications
Mobile backends

📈 Example: Public E-commerce Website
Scenario:
You’re hosting an online store on OCI.
You have 3 backend web servers (Compute Instances) inside a VCN.
You set up a Public Load Balancer on port 443 (HTTPS) in front of these instances.
Internet Users
     |
     v
[Public Load Balancer - HTTPS 443]
     |
     |--- Web Server 1
     |--- Web Server 2
     |--- Web Server 3

The load balancer has a public IP, so users can reach it via https://myonlinestore.com
It terminates SSL, distributes load, and checks server health

🚦 Security:
OCI uses Security Lists or Network Security Groups (NSG) to allow traffic from 0.0.0.0/0 (public internet)
You can limit IPs using NSG or a Web Application Firewall (WAF)

✅ Common Use Cases:
Hosting websites (www.example.com)
Internet-facing APIs (api.example.com)
Admin panels with 2FA or login
Mobile/web backends

🔒 2. Private Load Balancer

📘 Definition:
A Private Load Balancer has a private IP address and is only accessible inside your Virtual Cloud Network (VCN) — not exposed to the public internet.

🔐 When to Use It: Use a private load balancer when:
You want to balance internal services
The app is used only by other systems inside your network
You are connecting between tiers (frontend to backend, microservices, etc.)

🏢 Example: Internal Microservices Communication
Scenario:
You’re running an internal inventory management system in OCI. It’s accessed only by employees connected via VPN or by another frontend app.

Frontend App (Internal)
     |
     v
[Private Load Balancer - HTTP 80]
     |
     |--- Inventory Service 1
     |--- Inventory Service 2
     |--- Inventory Service 3

No public IP is assigned to the load balancer
Only internal services/subnets can access it
Improves security by limiting exposure

✅ Common Use Cases:
Backend microservices communication
Internal APIs
Database proxies (e.g., MySQL cluster)
Private corporate dashboards
Multi-tier application architectures

🔐 Security for Private LB:
Only accessible via:
OCI compute instances in the same VCN
On-prem systems over VPN or FastConnect
No internet access unless routed through NAT Gateway or Bastion Host

🧾 Summary: Public vs Private Load Balancer

Feature	                        Public LB	                  Private LB

IP Address	                        Public IP	                  Private IP (VCN only)
Internet Accessible	            ✅ Yes	                  ❌ No
Use Case	                        Web apps, APIs, 	            Internal services, microservices
                                    internet traffic
Common Ports	                  80 (HTTP), 443 (HTTPS)	      Any internal port (e.g., 8080, 1521)
Access Control	                  Security List + WAF	      NSG + Private routing
Security Risk	                  Higher, requires hardening    Lower, isolated to VCN

📌 Which One Should You Use?

If you want to...	                                        Use

Host a website	                                    ✅ Public LB
Handle API calls from mobile users	                  ✅ Public LB
Distribute traffic between backend microservices	✅ Private LB
Protect a DB access point internally	            ✅ Private LB
Serve internet users securely via HTTPS	            ✅ Public LB + SSL


____________________________________________________________________________________________________________________________________________________________________________

✅ What is a Health Check?
A health check is an automated test that a load balancer performs to continuously monitor the status (health) of backend servers (the servers that actually serve 
your application). The goal is to make sure only healthy, available servers receive traffic, improving reliability and availability.

🌐 How Health Checks Work
-> The load balancer regularly (based on a time interval you choose) performs a health check on each backend server.
-> If a server passes the health check, it stays in rotation and continues to receive traffic.
-> If a server fails the health check, the load balancer temporarily removes it from the pool (it stops sending new traffic to that server).
-> If the failed server later passes the health check, it is returned to rotation and starts receiving traffic again.

🌐 Types of Health Checks
# TCP-Level Health Checks
->The load balancer tries to establish a basic TCP connection (the “three-way handshake”) with the backend server.
-> If the connection can be made, the server is marked as healthy.
-> This checks whether the server is up and reachable, but it doesn’t check if the application itself is running properly.

🌐 HTTP-Level Health Checks
-> The load balancer sends an HTTP request (to a specific URI you configure) to the backend server.
-> It evaluates the server’s health based on the HTTP status code (e.g., 200 OK) or the content of the response.
-> More advanced than TCP checks, as you can confirm your actual application is responding as expected.

🌐 SSL with TCP/HTTP Health Checks
-> You can use SSL (or TLS) with either TCP or HTTP health checks for secure environments.
-> For HTTP checks with SSL enabled, the load balancer uses HTTPS to contact the server.

🌐 Why Use Health Checks?
Increase Availability: Automatically remove unhealthy servers, so users get a working response.
Reduce Downtime: Quickly detect and respond to backend failures without human intervention.
Maintenance: Lets you take backend servers down for maintenance without affecting user experience (the load balancer will detect and stop routing traffic to them).

🌐 Health Status Indicators
-> The load balancer dashboard shows the health (up, down, etc.) of each backend server.
-> It displays counters (badges) for the number of servers at each health status level.
      ~ A filled badge means the counter matches the overall health status.
      ~ An outlined badge with no fill means that status has zero servers.

# Example:
2 servers healthy (green badge filled)
1 server unhealthy (red badge outlined)

Summary Table
Check Type	      What It Tests	                  When It's Used
TCP	            Server/network is up & reachable	Basic health, network-level apps
HTTP	            App is running & responding OK	Web apps, API endpoints
SSL	            Secure health checks	            Secure apps, HTTPS endpoints

In Short:
Health checks keep your load balanced app reliable and resilient.
They automatically monitor, remove, and re-add backend servers based on health.
You can choose simple (TCP) or deep (HTTP) checks, with or without SSL.
Let me know if you want to see configuration examples or have questions about how to set up health checks!

___________________________________________________________________________________________________________________________________________________________________________
What is SSL? SSL (Secure Sockets Layer)
-> SSL stands for Secure Sockets Layer.It is a standard security protocol for establishing encrypted links between a client (usually a web browser) and a server 
(typically a website).
-> TLS (Transport Layer Security) is the modern, more secure successor to SSL, but the term "SSL" is still widely used to refer to both protocols.

# Purpose
Encryption: Protects data from being read by third parties during transmission.
Authentication: Verifies that the server (and sometimes the client) is who they claim to be.
Data Integrity: Ensures data isn't altered during transit.

# How SSL Works (Basic Steps)
Handshake: Client and server negotiate the SSL protocol version and cryptographic algorithms.
Certificate Exchange: The server provides an SSL certificate to the client, proving its identity.
Key Exchange: Client and server agree on encryption keys.
Encrypted Session: All subsequent data is encrypted using these keys.


What is an SSL/TLS Certificate?
Definition:
An SSL/TLS certificate is a small data file installed on a server that acts as a digital passport, proving the server’s identity and enabling secure (encrypted)
connections between the server and clients (e.g., browsers).

# Function:
Authentication: Confirms the server is who it says it is.
Encryption: Enables encrypted communication using SSL or TLS, protecting data in transit.
How it Works:

When a client (like your browser) connects to a server (website) over HTTPS, the server sends its certificate.
The client checks the certificate’s validity and the identity of the certificate authority (CA) that issued it.
If valid, the client and server establish an encrypted connection.

What Information Does a Certificate Contain?
Domain name (e.g., www.example.com)
Organization name and location
Certificate Authority (CA) that issued it
Public key
Validity period (start/end date)
Signature of the CA

Are SSL and TLS Certificates Different?
No—they are essentially the same thing. The industry still often says “SSL certificate” out of habit, but all modern certificates work with TLS, and SSL protocols 
are obsolete.


________________________________________________________________________________________________________________________________________________________________________

🔐 What is WAF (Web Application Firewall) in OCI?

A WAF is a cloud-based security service that monitors, filters, and blocks malicious HTTP/HTTPS traffic to your web applications.

In OCI, WAF protects web-facing apps hosted on:
OCI Load Balancers
Web Application URLs
Content Delivery Networks (CDNs)

🔍 How It Works:

-> WAF sits in front of your application (usually behind a load balancer or edge service) and analyzes incoming HTTP/S requests.
-> If a request looks malicious, it gets blocked before reaching your app.

🎯 Why Is WAF Important?

Problem	                              Without WAF
SQL injection	            App database can be accessed or destroyed
Cross-site scripting (XSS)	Users can be hacked through your app
Bot attacks	                  Bots can overload or exploit your site
Application DDoS	            Your app might crash due to fake traffic
Zero-day exploits	            You have no protection against new threats


➡️ WAF defends against all of the above.
🧠 What Attacks Can OCI WAF Block?

Attack                                   Type Description
SQL Injection	                  Injecting SQL to access/modify database
Cross-Site Scripting (XSS)	      Injecting scripts into user browsers
Remote File Inclusion (RFI)	      Loading malicious files from URLs
Cross-Site Request Forgery (CSRF)	Unauthorized commands sent from a trusted user
DDoS (Layer 7)	                  Application layer attacks
Bad Bots	                        Automated tools scraping or attacking your site


🛠️ How OCI WAF Works (Simplified Flow)

Client Request
     ↓
[ Oracle WAF ]
     ↓
[ Load Balancer (HTTPS) ]
     ↓
[ Backend Web Servers ]

1. Client sends HTTP request
2. WAF checks for threats
3. If clean → forward to Load Balancer → Backend server
4. If malicious → block/alert

🧪 Example Use Case: Secure Public Web App

Scenario: You're hosting a public e-commerce app behind a public Load Balancer.

# Without WAF:
-> A hacker might try to inject SQL via the search box:
-> ' OR '1'='1
-> If successful, they could read or delete your database.

# With WAF:
-> The rule engine detects the SQL pattern
-> The request is blocked instantly
-> Admin is notified

✅ Benefits of Using WAF

Advantage	                  Explanation

Blocks attacks	      Protects against OWASP Top 10, bots, and more
Cloud-managed	      No setup required on your app server
Custom rules	      Define what’s allowed or denied
Geo-blocking	      Block traffic from specific regions
DDoS Protection	      Basic layer 7 defense
Logging & Visibility	See all traffic and threats in logs

❌ What Happens If You Don’t Use WAF?

Consequence	            Risk

Data Breach	            Attackers can steal or modify your database
Downtime	            DDoS or bots can crash your site
Customer Loss	      If user data is exposed, they leave
Legal Trouble	      You may violate GDPR, PCI-DSS, HIPAA, etc.
Financial Loss	      Fines, lawsuits, and brand damage

📉 Limitations / Cons of WAF

Limitation	                  Detail

False Positives	      Sometimes blocks valid traffic if rules are too strict
Latency	            Slight increase in response time due to inspection
Cost	                  OCI WAF is a paid service, not free like NSG
Not 100% secure	      WAF is a layer of defense, not a complete security solution

📌 Summary Table

Feature	                  Details

What is WAF?	      A firewall for HTTP/HTTPS traffic
Where to use?	      In front of public-facing web apps
Protects from?	      SQLi, XSS, CSRF, bots, DDoS, OWASP top 10
How it's deployed?	In OCI as a policy attached to a load balancer or domain
Why important?	      Prevents attacks, protects data, ensures compliance
What if not used?	      App is open to common and dangerous web threats

🔐 Best Practices
✅ Always use WAF for public-facing apps
✅ Enable OWASP Top 10 ruleset
✅ Monitor WAF logs for attack trends
✅ Test your app after WAF rules to avoid false positives
✅ Combine WAF with SSL, NSGs, and Authentication


         +--------------------+
         |    Internet User   |
         +---------+----------+
                   |
                   v
           +------------------+
           |     OCI WAF      |  <-- Sits at the edge, outside the VCN
           +------------------+
                   |
                   v
         +----------------------+
         |   Internet Gateway   |
         +----------------------+
                   |
                   v
         +----------------------+
         |         VCN          |
         |  +----------------+  |
         |  |  Load Balancer |  |  (optional)
         |  +----------------+  |
         |      |      |        |
         |   Subnet  Subnet     |
         |   (VMs)   (VMs)      |
         +----------------------+
